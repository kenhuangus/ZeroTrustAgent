# LLM Configuration
# Set to 'true' to use OpenAI's GPT model, 'false' to use local Ollama
# For Replit environments, it's recommended to set this to 'true'
# as Ollama may not be available in the cloud environment
USE_REMOTE_LLM=true

# OpenAI API configuration (required when USE_REMOTE_LLM=true)
OPENAI_API_KEY=your_api_key_here